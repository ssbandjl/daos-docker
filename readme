vscode filter:
*.c, *.h, readme, *sh, *.py, *.go


cart流程:
1. 日志初始化/注册协议和操作码 crt_init_opt
2. 创建上下文（fabric->domain->endpoint->cq...） crt_context_create
3. 创建请求 crt_req_create / crt_corpc_req_create RPC请求集合 传入目的端点 -> ep_rank
4. 发送请求（请求跟踪和取消跟踪） crt_req_send / dss_rpc_send
5. 查看请求进度和回调（progress和trigger） crt_progress
6. 发送回复 crt_reply_send / crt_reply_get



hg_example:
server:
main -> HG_Set_log_level -> HG_Init -> HG_Init_opt -> HG_Core_init_opt -> HG_Core_set_more_data_callback

crt_context_create -> ... ->  HG_Core_init_opt -> hg_core_init -> NA_Initialize_opt -> na_info_parse 解析网络抽象信息 -> na_class_table -> check_protocol 检查协议 -> initialize 初始化 -> na_ofi_initialize 网络抽象初始化 -> na_ofi_check_interface 检查接口(getaddrinfo/getifaddrs/inet_ntop) -> HG_QUEUE_INIT(&priv->addr_pool) 初始化地址池 -> na_ofi_domain_open 打开域 -> na_ofi_getinfo 先查看信息 -> fi_fabric/fi_domain 分配保护域数据 ibv_alloc_pd -> hg_mem_pool_create 创建内存池 -> na_ofi_addr_create 创建地址,设置长度,放入地址池 -> na_ofi_endpoint_resolve_src_addr -> fi_getname -> vrb_dgram_ep_getname ->  
na_ofi_get_uri -> fi_av_straddr -> char *ofi_straddr -> na_ofi_addr_ht_lookup 查找或插入 -> src_addr = na_ofi_addr 设置端点源地址

fi_av_insert 将地址插入到地址向量




查池 ... -> ds_pool_query_handler -> pool_space_query_bcast -> bcast_create -> ds_pool_bcast_create -> crt_corpc_req_create -> crt_corpc_info_init 集体rpc初始化 -> crp_coll = 1 -> ...
 
crt_req_send -> crt_corpc_req_hdlr rpc请求集合控制器 -> co_pre_forward 转发前执行, 比如 ds_mgmt_tgt_map_update_pre_forward -> crt_tree_get_children -> crt_req_create_internal 创建N个内部请求 for (i = 0; i < co_info->co_child_num; i++) -> corpc_add_child_rpc 添加子rpc -> crt_req_send 回调(crt_corpc_reply_hdlr) 先发子RPC -> crt_rpc_common_hdlr  -> 发送后执行回调 crt_hg_req_send_cb -> 执行回调 crp_complete_cb -> crt_corpc_reply_hdlr

发送后
接收方(目标rank): crt_rpc_handler_common -> crt_corpc_common_hdlr -> crt_bulk_create -> crt_bulk_transfer -> 完成回调 crt_corpc_chained_bulk_cb -> crt_corpc_initiate 发起集体rpc -> crt_corpc_info_init -> crt_corpc_req_hdlr



corpc_add_child_rpc -> 继承父rpc部分属性 -> 将rpc插入co_child_rpcs尾部 -> 

map_update
ds_mgmt_tgt_map_update_pre_forward -> ds_mgmt_group_update


crt_tree_get_children -> CRT_TREE_PARAMETER_CHECKING -> crt_get_filtered_grp_rank_list 获取target组 -> to_get_children_cnt -> crt_knomial_get_children_cnt -> 


crt_corpc_reply_hdlr -> crt_corpc_complete

crt_corpc_reply_hdlr -> 


crt_corpc_req_hdlr -> 

SHIFT: 移位运算

树:
branch_ratio – 分支比率，对于 CRT_TREE_FLAT 被忽略。 对于 KNOMIAL 树或 KARY 树，有效值应在 [CRT_TREE_MIN_RATIO, CRT_TREE_MAX_RATIO] 范围内，否则将被视为无效参数
grp_rank_list 是用于构建树的目标组（在应用 filter_ranks 之后），其中的排名号用于主要组





rsvc_hash


Put a replicated service reference: 放置一个复制的服务参考

停止 RDB 副本数据库。 db 中的所有 TX 必须已经结束或仅在 rdb 中阻塞。


filter_invert: 倒置过滤

docker build  . -f utils/docker/Dockerfile.centos.7 -t daos:2.0.1

curl -sSfL --retry 10 --retry-max-time 60 -o ofi_patch_001 https://raw.githubusercontent.com/daos-stack/libfabric/master/daos-9173-ofi.patch
curl -sSfL --retry 10 --retry-max-time 60 -o ofi_patch_002 https://raw.githubusercontent.com/daos-stack/libfabric/master/daos-9376-ofi.patch
/home/daos/pre/build/external/release/ofi_patch_001

/home/daos/cache/patch/ofi_patch_001

resolve_patches


➜  daos git:(heads/v2.0.1) ✗ docker --version
Docker version 20.10.12, build e91ed57

online:
cd /root/github/storage/daos/docker
docker build https://github.com/daos-stack/daos.git\#v2.0.1 -f utils/docker/Dockerfile.centos.7 -t daos

local_tree:
git clone --recurse-submodules https://github.com/daos-stack/daos.git -b v2.0.1
docker build  . -f utils/docker/Dockerfile.centos.7 -t daos


docker stop server && docker rm server
docker run -it -d --privileged --cap-add=ALL --name server -v /root/github/storage/daos/origin/docker:/home/daos/docker -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1

docker run -it -d --privileged --cap-add=ALL --name daos1 -v /root/github/storage/daos/origin/docker:/home/daos/docker -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1
docker run -it -d --privileged --cap-add=ALL --name daos1 -v /root/github/storage/daos/origin/docker:/root/github/storage/daos/origin/docker -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1

docker run -it -d --privileged --cap-add=ALL --name daos2  -p 22223:22 -p 31436:31416 -v /root/github/storage/daos/origin/docker:/home/daos/docker -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1

docker run -it -d --privileged --cap-add=ALL --name centos  -p 22222:22 -p 5555:5555 -v /root/project/stor/ceph/xb/docker/ceph:/root/project/stor/ceph/xb/docker/ceph 

/root/project/stor/ceph/xb/docker/ceph

61:
docker run -it -d --privileged --cap-add=ALL --name daos1 -v /home/xb/project/stor/daos/origin/docker/daos:/home/xb/project/stor/daos/origin/docker/daos -v /dev:/dev -v /dev/hugepages:/dev/hugepages -v /sys/fs/cgroup:/sys/fs/cgroup:ro daos:2.0.1
docker exec -u root -it daos1 bash -c 'cd /home/xb/project/stor/daos/origin/docker/daos;exec "${SHELL:-sh}"'


docker exec -it -u root server /bin/bash
export FI_LOG_LEVEL=debug
daos_server start -o /home/daos/daos/utils/config/examples/daos_server_local.yml

拷贝配置文件:
echo 'export PATH=/opt/daos/bin:$PATH' >> /root/.bashrc
mkdir -p /opt/daos/etc/
mkdir -p /etc/daos/certs
rm -f /opt/daos/etc/*.yml && cp utils/config/*.yml /opt/daos/etc/ && cp -r utils/config/examples/certs /etc/daos/
source /root/.bashrc

改权限:
chmod 0700 /etc/daos/certs/agent.key
chmod 0700 /etc/daos/certs/server.key
chmod 0700 /etc/daos/certs/admin.key


dmg sto scan
dmg net scan
dmg -i storage format
dmg storage format

dmg system erase

# -e TZ=Asia/Shanghai
docker run -it -d --privileged --cap-add=ALL --name server -v /dev:/dev -v /dev/hugepages:/dev/hugepages daos
docker exec server daos_server start -o /home/daos/daos/utils/config/examples/daos_server_local.yml
docker exec server dmg -i storage format

daos1(){
	
  docker exec -u root -it daos bash -c 'cd /root/github/storage/daos/origin/docker/daos;exec "${SHELL:-sh}"'
}

vim /home/daos/daos/utils/config/examples/daos_server_local.yml
- D_LOG_MASK=DEBUG
- DD_SUBSYS=all
- DD_MASK=all


教程:
tour.md
创建池/创建容器
dmg system query -v
dmg pool create sxb -z 4g
dmg pool list -v
dmg pool query sxb
daos cont create --oclass=RP_3GX --properties=rf:1 --type POSIX --pool sxb --label sxb
daos container create --pool sxb --type POSIX --label sxb
daos container --verbose query -p sxb -c sxb


调试:
dlv exec /opt/daos/bin/daos -- cont create --oclass=RP_3GX --properties=rf:1 --type POSIX --pool sxb --label sxb
gdb /opt/daos/bin/daos
set args cont create --oclass=RP_3GX --properties=rf:1 --type POSIX --pool sxb --label sxb1

池
gdb /opt/daos/bin/dmg
set args pool create sxb -z 4g
b xxx 
r


查容器:
daos cont query sxb sxb


挂载/卸载
mkdir -p /tmp/sxb
dfuse --mountpoint=/tmp/sxb --pool=sxb --cont=sxb
cd /tmp/sxb

umount /tmp/sxb

查看系统调用
strace -o xxx.log -fff exec -f config_file



参考: DaosObjectType.java
oclass: 对象类型(object class), 具有明确布局的副本对象, 第一个数字是副本数，G后面的数字代表冗余组的数量
2G1 : 2个副本, 分布在冗余组1
8GX : 8 个副本，它分布在池中的所有目标上


kill engine:
ps aux|grep '/opt/daos/bin/daos_engine'|grep -v grep|awk '{print$2}'|xargs kill -9

tail -f /tmp/daos_*.log

pkill daos_agent daos_server
daos_agent
daos_server start

pkill daos_agent daos_server;daos_agent & daos_server start

dmg server set-logmasks ERR,mgmt=debug,cart=debug,hg=debug,external=debug,object=debug

dmg server set-logmasks debug

umount /mnt/sxb

mkdir /mnt/sxb
dfuse --m=/mnt/sxb --pool=sxb --cont=sxb
cd /mnt/sxb

for i in {0..5};do
  echo "$i, `date`"
  dd if=/dev/zero of=$i bs=1M count=100 oflag=direct
  sleep 3
done

docker
pc(client) -> ssh -> ubuntu(code) -> map_volume -> docker
cp -r /home/daos/pre/build .


DAOS Tour test


code:




FI_ORDER_SAS: send after send

struct ofi_prov		*next: 提供者是一个单向链表



scons build:
require -> comp_def.configure() -> comp_def.build -> if has_changes or self.has_missing_targets

rebuild mercury, site_scons/prereq_tools/base.py, 
def _has_changes(self)
  if self.name == mercury:...
build cache
rm -f .sconsign.dblite

find . -name "mercury_config.h"
readlink -f ./mercury.build/src/mercury_config.h

头文件搜索路径:
export C_INCLUDE_PATH=$C_INCLUDE_PATH:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury.build/src/na:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury.build/src:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src/na:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src/util:/home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/src/proc_extra

echo '/lib64/' >> /etc/ld.so.conf
ldconfig
ldconfig -p|grep mercury
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/lib64/:/opt/daos/prereq/debug/mercury/lib/:/opt/daos/prereq/debug/mercury/include/
cd /home/xb/project/stor/daos/origin/docker/daos/build/external/debug/mercury/mercury/build/05_bulk
make



git commit --amend
git format-patch -1

reset single file
git checkout HEAD -- fi_domain.h


性能调优: https://docs.daos.io/v2.0/admin/performance_tuning/
As an example, an engine with targets: 16 and nr_xs_helpers: 4 would use the following tag distributions:
tag 0: metadata service
tag 1: monitoring service
tag 2-17: targets 0 to 15 (16 targets total)
tag 18-21: helper service

self_test:
export D_LOG_MASK=debug
export DD_SUBSYS=all
export DD_MASK=all

self_test -u --group-name daos_server --endpoint 0:2 --message-size '(b1048578 b1048578)' --max-inflight-rpcs 16 --repetitions 100
self_test -u --group-name daos_server --endpoint 0:2 --message-size '(0 0)' --max-inflight-rpcs 16 --repetitions 1000

主流程
main(int argc, char *argv[]) -> d_log_init -> 解析和校验参数 -> run_self_test -> cleanup

run_self_test -> 定义 latencies 内存结构 -> self_test_init 初始化cart -> crt_group_rank -> crt_group_lookup -> qsort 排序 -> d_iov_set -> crt_bulk_create -> test_msg_size -> cleanup

self_test_init -> crtu_test_init -> dc_agent_init 获取socket_path -> crtu_dc_mgmt_net_cfg_setenv 设置环境变量 -> crt_init 初始化传输层(crt_init_opt) crt_self_test_init 全局锁 -> crt_context_create -> crt_group_view_create -> crtu_dc_mgmt_net_cfg_rank_add -> progress_fn 推进rpc crt_progress -> crt_group_ranks_get 查找某个组的ranks -> crt_group_psr_set 设置服务主rank -> crtu_wait_for_ranks -> crt_rank_self_set 设置自己的rank


crt_init_opt -> d_log_init -> crt_setup_log_fac -> data_init 初始化全局配置/流控 -> prov_data_init 设置属性 -> crt_hg_init HG/NA日志初始化 -> crt_grp_init -> crt_plugin_init 回调 -> crt_self_test_init -> crt_opc_map_create -> crt_internal_rpc_register -> crt_proto_register_internal(&cpf) -> crt_proto_register -> crt_opc_reg_internal -> crt_opc_reg 设置属性 回调 -> opc_info->coi_crf = crf 操作码信息_crt请求格式, 控制器

crt_opc_map_create -> crt_opc_map_L2_create

crt_grp_init -> crt_primary_grp_init -> crt_grp_priv_create -> grp_priv_init_membs -> crt_grp_lc_create


cg_credit_ep_ctx: 流控, 每个目标EP CTX的inflight RPC 的积分限制

crt_context_create:
crt_context_provider_create -> 网络抽象初始化 -> ofi建连接(走内核,成本高) ->  内存池, 地址池(priv->addr_pool), 地址hash表(domain->addr_ht) -> 


crt_context_create -> crt_context_provider_create -> crt_context_init -> crt_hg_ctx_init -> crt_hg_get_addr -> d_list_add_tail 插入链表尾部 -> crt_provider_inc_cur_ctx_num 上下文索引号自增 -> 启动传感器sensors? -> crt_provider_name_get 获取提供者名 -> d_tm_add_metric 添加指标 -> crt_swim_init 初始化swim? -> 慢网(sockets/tcp_rxm)


crt_context_init -> d_binheap_create_inplace crt_timeout_bh_ops cc_bh_timeout -> d_hash_table_create_inplace epi_table_ops cc_epi_table


crt_hg_ctx_init -> crt_hg_class_init -> HG_Context_create -> HG_Context_set_data -> crt_hg_pool_init

crt_hg_class_init -> crt_get_info_string -> HG_Init_opt -> crt_hg_get_addr -> crt_hg_reg_rpcid


HG_Init_opt -> HG_Core_init_opt -> HG_Core_set_more_data_callback

HG_Core_init_opt -> hg_core_init -> NA_Initialize_opt -> NA_Msg_get_max_tag  na_ofi_msg_get_max_tag -> hg_hash_table_new

NA_Initialize_opt -> na_info_parse 解析和填充主机信息 -> check_protocol 先检查协议 na_ofi_check_protocol -> initialize na_ofi_initialize

na_ofi_initialize -> na_ofi_prov_name_to_type -> na_ofi_check_interface -> HG_QUEUE_INIT(&priv->addr_pool) 初始化地址池 -> na_ofi_domain_open -> hg_mem_pool_create -> 


HG_Context_create -> 


crt_group_view_create 创建本地组视图(仅客户端) -> crt_grp_priv_create 初始化链表 -> grp_priv_init_membs -> crt_grp_lc_create uri和地址查找缓存lookup_cache -> d_list_add_tail 将gp_link插入全局链表

crtu_dc_mgmt_net_cfg_rank_add 管理网络配置/添加rank -> dc_get_attach_info 获取附着信息(包含所有rank的uri) -> crt_group_primary_rank_add 将uri插入crt上下文的查找缓存表中, 针对0号tag, 将rank加入组成员列表中

crt_progress -> crt_hg_progress poll cq -> crt_context_timeout_check 超时检查 -> crt_exec_progress_cb


crtu_wait_for_ranks -> sem_init -> crt_req_create -> crt_req_set_timeout -> crt_req_send -> crtu_sync_timedwait
crt_req_create -> crt_req_create_internal -> crt_rpc_priv_alloc 分配rpc请求私有数据 -> crt_rpc_priv_init 设置初始状态:rpc_priv->crp_state = RPC_STATE_INITED -> crt_opc_lookup 查找操作码 


RPC_STATE_INITED -> 

查找目标地址:
crt_req_send -> crt_req_send_internal -> crt_req_ep_lc_lookup -> crp_hg_addr (na_addr) -> 地址作为 HG_Create 的参数(目的地址) -> crt_req_send_immediately -> crt_hg_req_create RPC_STATE_REQ_SENT 创建请求,设置状态为发送 -> crt_hg_req_send -> HG_Forward -> HG_Core_forward -> forward(hg_core_handle) -> hg_core_forward_na -> NA_Msg_send_unexpected -> na_ofi_msg_send_unexpected -> na_ofi_msg_send -> fi_tsend

目标地址: crp_tgt_uri
crt_req_send_internal -> crt_req_ep_lc_lookup -> crt_req_fill_tgt_uri -> crp_tgt_uri

crt_issue_uri_lookup


crt_hg_req_create -> 控制器复用:HG_Reset -> 不复用:HG_Create -> 



crt_hg_req_send -> HG_Forward(rpc_priv->crp_hg_hdl, crt_hg_req_send_cb 由HG转发(同时设置完成回调) -> 






复用控制器
rpc_priv->crp_hdl_reuse

coi_no_reply:1 /* one-way */ 单程(无需响应,默认)


test_msg_size -> crt_req_create -> 

crt_req_create(crt_ctx, endpt, CRT_OPC_SELF_TEST_START
CRT_OPC_SELF_TEST_STATUS_REQ -> crt_bulk_transfer -> crt_hg_bulk_transfer -> HG_Bulk_transfer_id, HG_Bulk_transfer -> hg_bulk_transfer -> hg_bulk_transfer_na -> hg_bulk_na_put -> NA_Put -> put -> na_ofi.c -> na_ofi_put -> na_ofi_rma fi_writemsg -> writemsg -> vrb_msg_ep_rma_writemsg -> wr.opcode = IBV_WR_RDMA_WRITE -> vrb_send_iov -> vrb_post_send -> ibv_post_send



crt_bulk_create -> crt_hg_bulk_create -> HG_Bulk_create -> hg_bulk_create -> hg_bulk_create_na_mem_descs -> hg_bulk_register -> NA_Mem_handle_create mem_handle_create -> NA_Mem_register na_ofi_mem_register -> fi_mr_regv -> fi_mr_key


crt scons 编译:
gurt/SConscript
cart/SConscript
cart_ctl
export D_LOG_MASK=DEBUG
export DD_MASK=all
export DD_SUBSYS=all
cart_ctl enable_fi -g daos_server -u
Build cart_ctl -> cart_ctl.c -> main -> parse_args -> crtu_test_init -> dc_agent_init -> ctl_init -> d_log_fini

ctl_init -> crtu_cli_start_basic -> sem_init -> crtu_wait_for_ranks -> ctl_register_ctl -> crt_req_create -> crt_req_send ctl_cli_cb -> crtu_sem_timedwait


crtu_cli_start_basic -> crtu_dc_mgmt_net_cfg_setenv -> ctl_init -> crt_context_create -> crtu_progress_fn -> crt_group_view_create -> crtu_dc_mgmt_net_cfg_rank_add -> crt_group_size -> crt_group_ranks_get -> crt_group_psr_set

ctl_init -> crt_init_opt



crtu_test_init -> 

swim:
self_id:18446744073709551615, swim_prot_period_len:1000,swim_suspect_timeout:8000,swim_ping_timeout:900,sc_next_tick_time:94491384(10/23-15:32:10.61)
daos_server -> engine -> main(int argc, char **argv) -> parse(argc, argv) 解析参数 -> server_init -> d_tm_record_timestamp -> dss_srv_init -> dss_xstreams_init -> dss_start_xs_id -> dss_start_one_xstream -> ABT_thread_create -> dss_srv_handler -> crt_context_create -> crt_context_provider_create -> crt_swim_init -> swim_init

阻止所有除了故障之外可能的信号
engine -> server_fini

server_init -> daos_debug_init -> dss_engine_metrics_init -> drpc_init -> register_dbtree_classes -> dss_topo_init -> abt_init -> dss_module_init interface初始化 -> crt_init_opt 网络初始化-> dss_module_init_all -> vos,rdb,rsvc,security,mgmt,dtx,pool,cont,obj,rebuild 模块初始化 -> dss_srv_init 服务初始化


crt_context_provider_create -> crt_provider_inc_cur_ctx_num 创建crt上下文后,将index自增1 -> cpg_ctx_num++ -> crt_context_register_rpc_task 注册公用rpc控制器 -> crt_context_idx  ctx->cc_idx = cur_ctx_num ->

send_request -> crt_swim_send_request -> crt_ctx = crt_context_lookup(ctx_idx) -> ctx->cc_idx == ctx_idx -> crt_req_create(crt_ctx, &ep, opc, &rpc) -> crt_req_send(rpc, crt_swim_cli_cb, ctx)


crt_swim_init -> swim_init -> crt_swim_rank_add -> crt_proto_register -> crt_register_progress_cb(crt_swim_progress_cb, crt_ctx_idx, NULL) 设置回调 -> swim_progress
swim_init -> 设置上下文属性

swim_prot_period_len: ping周期(1000ms)
swim_suspect_timeout: 质疑超时(8000ms)

crt_proto_register -> crt_proto_register_common -> crt_proto_reg_L1 -> crt_proto_reg_L2 -> crt_proto_reg_L3

if (send_updates) -> swim_updates_send -> 


engine -> server_init -> crt_init_opt -> crt_grp_init -> crt_primary_grp_init -> crt_grp_priv_create -> grp_priv_init_membs -> crt_grp_lc_create


server_init -> dss_module_init_all -> dss_module_init_one -> sm_init() -> ds_mgmt_init -> ds_mgmt_system_module_init 

ubip_server -> cmd.start = server.Start -> func Start 启动服务 -> registerEvents 注册事件 -> OnLeadershipGained 获得领导力 -> startJoinLoop -> func (svc *mgmtSvc) joinLoop -> func (svc *mgmtSvc) doGroupUpdate -> MethodGroupUpdate -> DRPC_METHOD_MGMT_GROUP_UPDATE -> ds_mgmt_drpc_group_update (in MS leader 主服务器) -> ds_mgmt_group_update_handler -> ds_rsvc_request_map_dist 广播集群map -> ABT_cond_broadcast -> sc_map_dist -> mgmt_svc_map_dist_cb -> map_update_bcast map更新广播 -> crt_corpc_req_create 创建rpc集合请求 MGMT_TGT_MAP_UPDATE 目标map更新 -> crt_grp_priv_get_primary_rank -> crt_corpc_info_init  -> d_rank_list_dup_sort_uniq -> dss_rpc_send -> crt_reply_get

dss_rpc_send -> crt_req_send(rpc, rpc_cb, &eventual) -> 


ds_mgmt_drpc_group_update 更新组信息 map_version -> ds_mgmt_group_update_handler -> ds_mgmt_group_update 组更新  REPLACE -> init_map_distd -> map_distd ->  d_hash_rec_find(& -> crt_group_primary_modify 编辑主要组(原子增/删/替换) -> crt_group_mod_get 获取添加和删除列表 -> grp_add_to_membs_list 添加成员 / crt_group_rank_remove_internal 移除rank -> crt_swim_rank_add -> grp_lc_uri_insert_internal_locked 插入uri查找缓存 ->



请求异步集群位图分发。 这最终会触发 ds_rsvc_class.sc_map_dist，它必须由 rsvc 类实现。

MethodSetRank -> ds_mgmt_drpc_set_rank -> crt_rank_self_set -> grp_add_to_membs_list -> crt_provider_get_ctx_list -> crt_hg_get_addr -> crt_grp_lc_uri_insert


grp_add_to_membs_list -> grp_get_free_index -> crt_swim_rank_add -> grp_regen_linear_list


广播一个条件。 ABT_cond_broadcast() 向所有在条件变量 cond 上阻塞的服务员发出信号。 调用者不需要持有与 cond 关联的互斥锁。 如果当前没有服务员在 cond 上阻塞，则此例程无效。


集体传播的树形拓扑
k-nomial tree k项树是一种在软件中实现集体通信操作的有效方法。 与 n 叉树不同，k 项树中的子节点数量随着任务深度的增加而减少（即，没有任务的子节点比根节点多）。 优点是更早开始通信的任务执行更多的工作，从而减少了集体操作的总延迟。 相比之下，在 n-ary 树中，较早开始通信的任务会较早完成，但会增加总延迟。 概念通过 KNOMIAL_PARENT、KNOMIAL_CHILDREN 和 KNOMIAL_CHILD 函数支持 k-nomial 树，如下所述。

该图是随着时间向下流动的结构。 也就是说，对于在 2 项树上表示的多播操作，任务 0 在第一个时间步向任务 1 发送消息。 然后，任务 0 发送到任务 2，而任务 1 发送到任务 3。最后一步，任务 0 发送到任务 4，任务 1 发送到任务 5，任务 2 发送到任务 6，任务 3 发送到任务 7—— 全部同时进行。 假设计算中总共有八个任务，以下表达式也成立：



swim_member_new_remote -> 

swim状态机:
SCS_TIMEDOUT -> SCS_SELECT (第一次未获取到目标) -> 获取到有效目标 -> SCS_BEGIN


swim_member_update_suspected -> 

sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config
# sed 's@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd

CMD ["/usr/sbin/sshd", "-D"]
ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key
/usr/sbin/sshd


for ip in 172.17.0.3 172.17.0.4;do rsync -rucalpzv /opt/daos root@$ip:/opt/;done

run_all "sed -i s/DD_SUBSYS=all/DD_SUBSYS=swim,cart,mgmt/g /opt/daos/etc/daos_server.yml"
run_all "sed -i s/#- FI_LOG_LEVEL=debug/- FI_LOG_LEVEL=debug/g /opt/daos/etc/daos_server.yml"

run_all "sed -i /.*FI_LOG_LEVEL=.*/d /opt/daos/etc/daos_server.yml"
run_all "sed -i '/env_vars:/a \ \ - FI_LOG_LEVEL=debug' /opt/daos/etc/daos_server.yml"


Hybrid Logical Clock (HLC): hlc 混合逻辑时钟, 

ips2='172.17.0.2 172.17.0.3 172.17.0.4'
function run_all(){
	local command=$*
	if [[ $* == "" ]]; then
	    echo "$1 cmd"
	else
		for ip in $ips2; do
			echo -e  "\n\033[32m`date +'%Y/%m/%d %H:%M:%S'` $ip $*\033[0m"
                        if [[ $ip == '172.17.0.2' ]];then
                            ${command}
			else
			    ssh $ip "${command}"
                        fi
		done
	fi
}

crt_progress(dmi->dmi_ctx, dx->dx_timeout) 0ms -> crt_exec_progress_cb -> cb_func = cbs_prog[i].cpcp_func -> swim_progress

git format-patch -1 24ea9400e30d67458bb2b970b52b81d4fdfe8f59
git format-patch -1
#mac: cd /Users/xb/OneDrive/storage/daos && scp root@xb-ubuntu:/root/github/storage/daos/origin/docker/daos/0001-build-docker-image-release-v2.0.1.patch .



egrep -v 'grp_lc_uri_insert_internal_locked|prealloc_requests|grp_li_uri_set' daos_engine.0.log |less



查找时排除
build,cache,tests,


mochi rdma mercury bulk:
https://mochi.readthedocs.io/en/latest/mercury/05_bulk.html
客户端:
HG_Init -> HG_Context_create -> MERCURY_REGISTER -> HG_Addr_lookup -> lookup_callback  HG_Trigger HG_Progress -> HG_Create -> HG_Bulk_create -> HG_Forward -> save_completed 转发完成后回调 -> HG_Get_output -> assert

服务端:
build/external/debug/mercury/mochi/05_bulk/server.c
HG_Init -> ... -> MERCURY_REGISTER save -> HG_Get_input -> HG_Bulk_create -> HG_Bulk_transfer -> fwrite -> HG_Respond

dump
获取缓存uri:
cart_ctl get_uri_cache --group-name daos_server -u

查看上下文:
cart_ctl list_ctx --group-name daos_server -u --rank 1

cart_ctl get_pid --group-name daos_server -u --rank 0-2


操作码: CRT_CTL_RPCS_LIST -> cpf.cpf_name  = "ctl" -> 
crt_proto_rpc_format

opc_info->coi_rpc_cb 收到rpc请求时回调 hg_proc_info->rpc_cb = rpc_cb -> crt_handle_rpc  crt_rpc_common_hdlr -> 

crt_hg_reg -> crt_rpc_common_hdlr

调度:
req_kickoff_internal -> 




sched_run -> sched_start_cycle -> process_all -> d_hash_table_traverse(info->si_pool_hash, process_pool_cb, dx) 遍历一个哈希表，对每一项调用遍历回调函数。 一旦回调返回非零就中断 -> sri_req_cnt -> 
crt_context_register_rpc_task -> dss_rpc_hdlr rpc控制器 -> sched_req_enqueue 请求入队 -> sri_req_cnt



daos_obj_update


对象更新
obj_tgt_update -> ds_obj_remote_update -> DAOS_OBJ_RPC_TGT_UPDATE -> crt_req_send(req, shard_update_req_cb, remote_arg) 发送RPC -> 



engine -> for (;;) 一直循环 -> crt_progress -> crt_hg_progress -> HG_Progress 推进RPC -> HG_Trigger 触发回调


hg_atomic_queue_push completion_queue -> hg_thread_cond_signal

HG_Trigger -> HG_Core_trigger -> hg_core_trigger -> hg_completion_entry = hg_atomic_queue_pop_mc(context->completion_queue) 从完成队列中取出一个条目 -> hg_core_trigger_entry 根据条目内容触发 -> hg_cb(&hg_core_cb_info) 执行用户回调(最终执行crt_req_send传入的完成回调)


coi_no_reply -> CRT_HG_ONEWAY_RPCID: 单程rpc(禁用响应) 

发送请求
crt_req_send(req, shard_update_req_cb, remote_arg) 将用户回调设置为完成回调:crp_complete_cb, HG_Forward 在 crt_hg_req_send_cb 中执行完成回调:crp_complete_cb

查询:
查leader: dmg sys leader-query

打开err日志:
dmg server set-logmasks err


vos_tests: gdb /opt/daos/bin/vos_tests
set args -p 

启动容器:
daos_start_all

停止所有服务:
daos_stop_all


客户端:
文件系统操作表: dfuse_pool_ops

查看系统调用:
strace -fff test/write_file /tmp/sxb/test1


gdb调试fuse:
gdb attach `ps aux|grep dfuse|grep -v grep|awk '{print$2}'`

kill dfuse
kill -9 `ps aux|grep dfuse|grep -v grep|awk '{print$2}'`

gdb条件断点:
(gdb) b ds_obj_rw_handler if opc==DAOS_OBJ_RPC_FETCH







vos初始化
vos_db_init



bug:
停服务,引用计数不对
HG_Context_destroy
  hg_core_context_destroy 1 remaining


单元测试, daos_test, 
run_test.sh
  eq_test 事件队列测试

拦截库IL, 
ioil_do_writex
一个名为 libioil 的拦截库可用于 DFuse。 该库与 DFuse 结合使用，允许拦截 POSIX I/O 调用并通过 libdaos 直接从应用程序上下文发出 I/O 操作，而无需任何应用程序更改。 这为 I/O 数据提供了内核旁路，从而提高了性能
unified namespace integration: 集成统一命名空间

客户端
dfuse


git raft子项目: git submodule update && git submodule update

编译spdk:
cd build/external/debug/spdk
./configure --help
yum install ncurses-devel ncurses
./configure --prefix="/opt/daos/prereq/debug/spdk" --disable-tests --disable-unit-tests --disable-apps --without-vhost --without-crypto --without-pmdk --without-rbd --with-rdma --without-iscsi-initiator --without-isal --without-vtune --with-shared

Running commands in /home/xb/project/stor/daos/origin/docker/daos
command:cp -r cache/spdk /home/xb/project/stor/daos/origin/docker/daos/build/external/debug/spdk
Running commands in /home/xb/project/stor/daos/origin/docker/daos/build/external/debug/spdk
command:git checkout v21.07




qa:
spdk缺elftools
centos7
pip3 install pyelftools

spdk:
Install CentOS SCLo RH repository:
yum install centos-release-scl-rh
Install CUnit rpm package:
# yum install CUnit





调试手段
gdb step
1. add sleep 10s in init, src/engine/init.c:1093
2. gdb attach, break, continue
3. step


dlv调试go:
dlv exec /opt/daos/bin/daos_server -- start

证书:
container: mkdir -p /etc/daos/certs/
ubuntu: docker cp /root/github/storage/daos/origin/docker/daos/utils/config/examples/certs daos:/etc/daos/certs/

分配rpc:
crt_rpc_priv_alloc
crt_rpc_inout_buff_init

代码规范: 注释
/**
 * Set the timeout value for an RPC request.
 *
 * \param[in] timeout_sec      timeout value in seconds. value of zero will be
 *                             treated as invalid parameter.
 *
 * \return                     DER_SUCCESS on success, negative value if error
 */
int
crt_req_set_timeout(crt_rpc_t *req, uint32_t timeout_sec);


openssl/kdf.h, yum install -y openssl11-devel

安装依赖
source "$scriptsdir/pkgdep/$id.sh" -> centos.sh

code_flow
dfs_mount 挂载daos文件系统
spdk -> dfs_mount(ch->pool, ch->cont, O_RDWR, &ch->dfs)
	prop = daos_prop_alloc(0)
	daos_cont_query(coh, NULL, prop, NULL)
	entry = daos_prop_entry_get(prop, DAOS_PROP_CO_LAYOUT_TYPE)
	daos_acl_principal_to_uid(entry->dpe_str, &dfs->uid)
	DAOS_PROP_CO_ROOTS superblock or root
	open_sb(coh, false, dfs->super_oid, &dfs->attr, &dfs->super_oh)
	open_dir(dfs, NULL, amode | S_IFDIR, 0, &root_dir, 1, &dfs->root)
	if (amode == O_RDWR)
		daos_cont_alloc_oids(coh, 1, &dfs->oid.lo, NULL) 超级块OID=0, 根OID=1
	
打开文件系统
dfs_open(ch->dfs, NULL, daos->disk.name, mode, fd_oflag, daos->oclass, 0, NULL, &ch->obj)
	dfs_open_stat
ofi编译参数:
site_scons/components/__init__.py



信用积分
cg_credit_ep_ctx
等待队列: epi_req_waitq
发送完成后, 判断信用分和等待队列, 然后决定是否从等待队列搬运请求到发送队列


crt_req_timeout_hdlr
src/include/cart/api.h -> crt_req_abort



ch_rec_free
hop_rec_free
rdb_stop
rdb_raft_stop
	rdb_abort_raft_rpcs -> Abort all in-flight RPCs
		crt_req_abort
